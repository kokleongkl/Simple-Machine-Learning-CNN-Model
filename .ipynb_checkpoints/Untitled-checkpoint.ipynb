{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11998 images belonging to 3 classes.\n",
      "Found 3000 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From /home/kokleong/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/kokleong/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "{'Fucon': 4000, 'Pulin': 3998, 'Dhamotil': 4000}\n",
      "{0: 2.9995, 1: 3.001000500250125, 2: 2.9995}\n",
      "WARNING:tensorflow:From /home/kokleong/anaconda3/envs/deep-learning/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "24/24 [==============================] - 4s 147ms/step - loss: 0.4860 - acc: 0.7737\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48602, saving model to models/Best-weights-my_model-001-0.6900-0.6954.h5\n",
      "94/94 [==============================] - 31s 327ms/step - loss: 0.6897 - acc: 0.6954 - val_loss: 0.4860 - val_acc: 0.7737\n",
      "Epoch 2/15\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.4013 - acc: 0.8490\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48602 to 0.40134, saving model to models/Best-weights-my_model-002-0.4665-0.8121.h5\n",
      "94/94 [==============================] - 27s 282ms/step - loss: 0.4669 - acc: 0.8121 - val_loss: 0.4013 - val_acc: 0.8490\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.3774 - acc: 0.8690\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40134 to 0.37744, saving model to models/Best-weights-my_model-003-0.4284-0.8271.h5\n",
      "94/94 [==============================] - 27s 290ms/step - loss: 0.4283 - acc: 0.8271 - val_loss: 0.3774 - val_acc: 0.8690\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.3576 - acc: 0.8793\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37744 to 0.35762, saving model to models/Best-weights-my_model-004-0.3790-0.8492.h5\n",
      "94/94 [==============================] - 27s 290ms/step - loss: 0.3793 - acc: 0.8492 - val_loss: 0.3576 - val_acc: 0.8793\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.3338 - acc: 0.8900\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35762 to 0.33382, saving model to models/Best-weights-my_model-005-0.3599-0.8586.h5\n",
      "94/94 [==============================] - 27s 289ms/step - loss: 0.3600 - acc: 0.8586 - val_loss: 0.3338 - val_acc: 0.8900\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - 3s 127ms/step - loss: 0.3165 - acc: 0.8963\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33382 to 0.31649, saving model to models/Best-weights-my_model-006-0.3322-0.8711.h5\n",
      "94/94 [==============================] - 27s 290ms/step - loss: 0.3323 - acc: 0.8711 - val_loss: 0.3165 - val_acc: 0.8963\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.2887 - acc: 0.9033\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31649 to 0.28873, saving model to models/Best-weights-my_model-007-0.3159-0.8752.h5\n",
      "94/94 [==============================] - 27s 289ms/step - loss: 0.3159 - acc: 0.8752 - val_loss: 0.2887 - val_acc: 0.9033\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.3208 - acc: 0.8730\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28873\n",
      "94/94 [==============================] - 27s 287ms/step - loss: 0.3104 - acc: 0.8778 - val_loss: 0.3208 - val_acc: 0.8730\n",
      "Epoch 9/15\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.2675 - acc: 0.9220\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28873 to 0.26750, saving model to models/Best-weights-my_model-009-0.2930-0.8856.h5\n",
      "94/94 [==============================] - 27s 289ms/step - loss: 0.2930 - acc: 0.8856 - val_loss: 0.2675 - val_acc: 0.9220\n",
      "Epoch 10/15\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.2722 - acc: 0.9087\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26750\n",
      "94/94 [==============================] - 27s 288ms/step - loss: 0.2784 - acc: 0.8923 - val_loss: 0.2722 - val_acc: 0.9087\n",
      "Epoch 11/15\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.2578 - acc: 0.9147\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.26750 to 0.25776, saving model to models/Best-weights-my_model-011-0.2702-0.8971.h5\n",
      "94/94 [==============================] - 27s 287ms/step - loss: 0.2700 - acc: 0.8971 - val_loss: 0.2578 - val_acc: 0.9147\n",
      "Epoch 12/15\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.2337 - acc: 0.9330\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.25776 to 0.23375, saving model to models/Best-weights-my_model-012-0.2685-0.8966.h5\n",
      "94/94 [==============================] - 27s 290ms/step - loss: 0.2683 - acc: 0.8966 - val_loss: 0.2337 - val_acc: 0.9330\n",
      "Epoch 13/15\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.2292 - acc: 0.9333\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.23375 to 0.22923, saving model to models/Best-weights-my_model-013-0.2698-0.8959.h5\n",
      "94/94 [==============================] - 27s 290ms/step - loss: 0.2699 - acc: 0.8959 - val_loss: 0.2292 - val_acc: 0.9333\n",
      "Epoch 14/15\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.2348 - acc: 0.9413\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.22923\n",
      "94/94 [==============================] - 27s 287ms/step - loss: 0.2524 - acc: 0.9043 - val_loss: 0.2348 - val_acc: 0.9413\n",
      "Epoch 15/15\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.2494 - acc: 0.9257\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.22923\n",
      "94/94 [==============================] - 27s 289ms/step - loss: 0.2526 - acc: 0.9077 - val_loss: 0.2494 - val_acc: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Dhamotil': 0, 'Fucon': 1, 'Pulin': 2}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "#init check points\n",
    "filepath=\"models/Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#\n",
    "# Step 1: define the data generators.\n",
    "#\n",
    "# Data generators are on-the-fly image transformers and are the recommended\n",
    "# way of providing image data to models in Keras. They let you work with\n",
    "# on-disk image data too large to fit all at once in-memory. And they allow\n",
    "# you to preprocess the images your model sees with random image \n",
    "# transformations and standardizations, a key technique for improving model\n",
    "# performance. To learn more, see https://keras.io/preprocessing/image/.\n",
    "# \n",
    "\n",
    "\n",
    "# Our training data will use a wide assortment of transformations to try\n",
    "# and squeeze as much variety as possible out of our image corpus.\n",
    "# However, for the validation data, we'll apply just one transformation,\n",
    "# rescaling, because we want our validation set to reflect \"real world\"\n",
    "# performance.\n",
    "#\n",
    "# Also note that we are using an 80/20 train/validation split.\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1/255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2\n",
    "        )\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/new_training_set',\n",
    "                                                 target_size = (48, 48),\n",
    "                                                 batch_size = 128,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/new_test_set',\n",
    "                                            target_size = (48, 48),\n",
    "                                            batch_size = 128,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode = 'categorical')\n",
    "                                        \n",
    "\n",
    "\n",
    "\n",
    "# I found that a batch size of 128 offers the best trade-off between\n",
    "# model training time and batch volatility.\n",
    "batch_size = 128\n",
    "\n",
    "# 2: define the model \n",
    "# For the purposes of this article I based the core of my model on VGG16,\n",
    "# a pretrained CNN architecture somewhat on the simpler side. This version\n",
    "# of VGG16 is one trained on the famed ImageNet (http://www.image-net.org/)\n",
    "# which includes some fruits in its list of classes, so performance should\n",
    "# be decent. I add a new top layer consisting of a large-ish fully \n",
    "# connected layer with moderate regularization in the form of dropout.\n",
    "# There are 12 output classes, so the output layer has 12 nodes.\n",
    "#\n",
    "\n",
    "prior = keras.applications.VGG16(\n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    input_shape=(48, 48, 3)\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(prior)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu', name='Dense_Intermediate'))\n",
    "model.add(Dropout(0.3,name='Dropout_Regularization'))\n",
    "model.add(Dense(3, activation='softmax', name='Output'))\n",
    "\n",
    "\n",
    "# Freeze the VGG16 model, e.g. do not train any of its weights.\n",
    "# We will just use it as-is.\n",
    "for cnn_block_layer in model.layers[0].layers:\n",
    "    cnn_block_layer.trainable = False\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "\n",
    "# Compile the model. I found that RMSprop with the default learning\n",
    "# weight worked fine.\n",
    "model.compile(\n",
    "    optimizer=RMSprop(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: fit the model.\n",
    "#\n",
    "# Finally we fit the model. I use two callbacks here: EarlyStopping,\n",
    "# which stops the model short of its full 20 epochs if validation \n",
    "# performance consistently gets worse; and ReduceLROnPlateau, which \n",
    "# reduces the learning rate 10x at a time when it detects model \n",
    "# performance is no longer improving between epochs.\n",
    "#\n",
    "\n",
    "# Recall that our dataset is highly imbalanced. We deal with this\n",
    "# problem by generating class weights and passing them to the model\n",
    "# at training time. The model will use the class weights to adjust\n",
    "# how it trains so that each class is considered equally important to\n",
    "# get right, even if the actual distribution of images is highly \n",
    "# variable.\n",
    "\n",
    "import os\n",
    "labels_count = dict()\n",
    "for img_class in [ic for ic in os.listdir('dataset/new_training_set') if ic[0] != '.']:\n",
    "    labels_count[img_class] = len(os.listdir('dataset/new_training_set/' + img_class))\n",
    "print(labels_count)\n",
    "total_count = sum(labels_count.values())\n",
    "class_weights = {cls: total_count / count for cls, count in \n",
    "                 enumerate(labels_count.values())}\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "model.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=12000,\n",
    "    epochs=15,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=3000,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        checkpoint,\n",
    "        ReduceLROnPlateau(patience=2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_set.class_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = tf.keras.models.load_model('models/Best-weights-my_model-013-0.2698-0.8959.h5')\n",
    "\n",
    "test_image = tf.keras.preprocessing.image.load_img('20190606_105532.jpg',target_size=(48,48))\n",
    "test_image = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "#test_image = test_image.reshape(64, 64)\n",
    "\n",
    "\n",
    "result = model.predict(test_image,batch_size=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
